<?xml version="1.0" encoding="utf-8"?>
<test>

<name>JSON attributes</name>

<requires>
<sphinxql_keep_null/>
</requires>

<config>
common
{
	on_json_attr_error		= ignore_attr
	json_autoconv_numbers	= 1
}

indexer
{
	mem_limit				= 16M
}

searchd
{
	<searchd_settings/>
	collation_libc_locale = C
	collation_server = binary	
}

source test
{
	type			= mysql
	<sql_settings/>
	sql_query		= select * from test_table
	sql_attr_uint	= gid
	sql_attr_json	= j
}

index test
{
	source			= test
	path			= <data_path/>/test
}

source src1
{
	type			= mysql
	<sql_settings/>
	sql_query		= select *, 1 as gid, 'dummy' as title from json_src_table where id%3=1
	sql_attr_uint	= gid
	sql_attr_json	= j
}
source src2
{
	type			= mysql
	<sql_settings/>
	sql_query		= select *, 2 as gid, 'dummy' as title from json_src_table where id%3=2
	sql_attr_uint	= gid
	sql_attr_json	= j
}
source src3
{
	type			= mysql
	<sql_settings/>
	sql_query		= select *, 3 as gid, 'dummy' as title from json_src_table where id%3=0
	sql_attr_uint	= gid
	sql_attr_json	= j
}

index i1
{
	source			= src1
	path			= <data_path/>/i1
}

index i2
{
	source			= src2
	path			= <data_path/>/i2
}

index i3
{
	source			= src3
	path			= <data_path/>/i3
}

index loc
{
	type			= distributed
	local			= i1
	local			= i2
}

index dist
{
	type			= distributed
	agent			= <my_address/>:i1
	agent			= <my_address/>:i2
}

index dist1
{
	type			= distributed
	agent			= <my_address/>:i1
	agent			= <my_address/>:i2
	local			= i3
}

index loc1
{
	type			= distributed
	local			= i1
	agent			= <my_address/>:i2
}

index loc_field
{
	type			= distributed
	local			= test
	agent			= <my_address/>:i2
}

index dist_field
{
	type			= distributed
	agent			= <my_address/>:test
}

source src_case
{
	type			= mysql
	<sql_settings/>
	sql_query		= select *, 11 as gid, 'dummy' as title from json_case
	sql_attr_uint	= gid
	sql_attr_json	= j
}

index json_case
{
	source			= src_case
	path			= <data_path/>/case
}

index rt
{
	type = rt
	path = <data_path/>/rt
	rt_field = title
	rt_attr_json = data
}

source json_attr
{
	type			= mysql
	<sql_settings/>
	sql_query		= SELECT * from json_attr
	sql_attr_json	= json1
}

index json_attr
{
	source = json_attr
	path=<data_path/>/json_attr
}

index dist_str
{
	type = distributed
	agent = <my_address/>:json_attr
}

index rt1
{
	type = rt
	path = <data_path/>/rt1
	rt_field = title
	rt_attr_string = s1
	rt_attr_json = j1
}

source json_arrays
{
	type			= mysql
	<sql_settings/>
	sql_query		= SELECT * from json_arrays
	sql_attr_json	= j
}

index arrays
{
	source = json_arrays
	path=<data_path/>/json_arrays
}

source json_objects
{
	type			= mysql
	<sql_settings/>
	sql_query		= SELECT * from json_objects
	sql_attr_json	= j
}

index objects
{
	source = json_objects
	path=<data_path/>/json_objects
}

index dist_case
{
	type			= distributed
	agent			= <my_address/>:json_case
}

source json_inplace
{
	type			= mysql
	<sql_settings/>
	sql_query		= SELECT * from json_inplace
	sql_attr_uint	= gid
	sql_attr_json	= j
}

index json_inplace
{
	source = json_inplace
	path=<data_path/>/json_inplace
}

index json_inplace_rt
{
	type = rt
	path = <data_path/>/json_inplace_rt
	rt_field = title
	rt_attr_uint = gid
	rt_attr_json = j
}

index json_search
{
	type = rt
	path = <data_path/>/json_search
	rt_attr_json = j
	rt_attr_string = title
	rt_field = text
}

index json_order
{
	type = rt
	path = <data_path/>/json_order
	rt_attr_json = j
	rt_field = text
}

index json_toplevel
{
	type = rt
	path = <data_path/>/json_toplevel
	rt_attr_json = j
	rt_field = text
}


source json_up1
{
	type			= mysql
	<sql_settings/>
	sql_query		= SELECT 1, 'test me' t, '{"R158S": 901, "rom": 202, "t1":"A", "t2":"AB", T1:"C"}' j
	sql_attr_json	= j
}
index json_up1
{
	source = json_up1
	path=<data_path/>/json_up1
}
source json_up2
{
	type			= mysql
	<sql_settings/>
	sql_query		= SELECT 100, 'test me' t, '{"R158S": 100, "rom": 303, "t1":"B", "t2":"BC", T1:"D"}' j
	sql_attr_json	= j
}

index json_up2
{
	source = json_up2
	path=<data_path/>/json_up2
}
index dist_up
{
	type			= distributed
	agent		= <my_address/>:json_up1
	agent		= <my_address/>:json_up2
}

index json_remap
{
	type = rt
	path = <data_path/>/json_remap
	rt_attr_json = j1
	rt_attr_json = j2
	rt_field = text
}

source json_objects1
{
	type			= mysql
	<sql_settings/>
	sql_query		= SELECT * from json_objects1
	sql_attr_json	= j
}

index objects1
{
	source = json_objects1
	path=<data_path/>/json_objects1
}

source json_str_arrays
{
	type			= mysql
	<sql_settings/>
	sql_query		= SELECT * from json_str_arrays
    sql_attr_string	= title
	sql_attr_json	= j
}

index json_str_arrays
{
	source  = json_str_arrays
	path    = <data_path/>/json_str_arrays
}
</config>

<db_create>
CREATE TABLE `test_table` (
  `id` int(11) NOT NULL AUTO_INCREMENT,
  `gid` int(11) NOT NULL,
  `title` varchar(255) NOT NULL,
  `j` varchar(8192) NOT NULL,
  PRIMARY KEY (`id`)
);
</db_create>
<db_drop>DROP TABLE IF EXISTS `test_table`;</db_drop>
<db_insert>
INSERT INTO `test_table` VALUES
(1,1,'test one','{"name":"Alice","uid":123}'),
(2,1,'test two','{"name":"Bob","uid":234,"gid":12}'),
(3,2,'another doc','{"name":"Charlie","uid":345}'),
(4,2,'doc number four','{"name":"Damon","uid":456,"gid":23}'),
(5,3,'numeric fixup','{"12":345, "34":"567"}'),
(6,3,'numeric fixup contd','{"12":"346", "179":"971"}'),
(7,3,'strings over 256 bytes','{"long":"
You can run on for a long time
Run on for a long time
Run on for a long time
Sooner or later God\'ll cut you down
Sooner or later God\'ll cut you down

Go tell that long tongue liar
Go and tell that midnight rider
Tell the rambler, the gambler, the back biter
Tell \'em that God\'s gonna cut \'em down
Tell \'em that God\'s gonna cut \'em down
", "short":"ohai"}'),
(8,3,'stringvector test','{sv:["one","two","three"],gid:315}'),
(9,3,'empty','{}'),
(10,3,'empty v2',''),
(11,3,'all the bitnesses','{"t1":123456789,"t2":-123456789,
	"t3":3123456789,"t4":-3123456789,
	"t5":9876543210,"t6":-9876543210}'),
(12,3,'stringvector vs longer strings','{sv:["
Mary had a little lamb, whose fleece was white as snow.
And everywhere that Mary went, the lamb was sure to go.
It followed her to school one day which was against the rules.
It made the children laugh and play, to see a lamb at school.
And so the teacher turned it out, but still it lingered near.",
"another world, another time, the age of wonders"],
	"gid":316}'),
(13,3,'long numbers vs string to numeric fixup','{
	i1:"123",
	i2:"-123",	
	i3:"18446744073709551615",
	i4:"-18446744073709551615",
	i5:"9223372036854775807",
	i6:"9223372036854775808",
	i7:"9223372036854775809",
	i8:"-9223372036854775807",
	i9:"-9223372036854775808",
	i10:"-9223372036854775809",
	i11:"123abc",
	i12:"-123abc",
	f1:"3.15",
	f2:"16777217.123"}'),
(14,3,'floats','{
	f1:3.15,
	f2:-7.40,
	f3:65536.7,
	f4:16777217.123}'),
(15,3,'invalid json','{ this is not valid }'),
(16,4,'unescaping','{nick:"One\nTwo"}'),
(17,4,'unescaping','{nick:"One\\nTwo"}'),
(18,4,'unescaping','{nick:"One
Two"}')
</db_insert>
<db_create>CREATE TABLE `json_src_table` ( `id` int(11) NOT NULL, `j` varchar(8192) NOT NULL );</db_create>
<db_drop>DROP TABLE IF EXISTS `json_src_table`;</db_drop>
<db_insert>
INSERT INTO `json_src_table` VALUES
(1,'{"uid":123}'),
(2,'{"uid":234}'),
(3,'{"uid":345}'),
(4,'{"uid":456}'),
(5,'{"uid":567}'),
(6,'{"uid":678}'),
(7,'{"uid":123}'),
(8,'{"uid":567}'),
(9,'{"uid":345}'),
( 100, '' )
</db_insert>
<db_create>CREATE TABLE `json_case` ( `id` int(11) NOT NULL, `j` varchar(8192) NOT NULL );</db_create>
<db_drop>DROP TABLE IF EXISTS `json_case`;</db_drop>
<db_insert>
INSERT INTO `json_case` VALUES
(1,'{"Attr":123,	"aTTr":12,	"Str":"nope",		"STR":"yep"		}'),
(2,'{"Attr":23,				 			"Str":"nope",		"STR":"yep2"	}'),
(3,'{"Attr":123,	"aTTr":12,							"STR":"yep"		}'),
(4,'{"Attr":123,	"aTTr":212,	"Str":"nope11"							}'),
(5,'{"Attr":12,		 "aTTr":12														}'),
(6,'{											"Str":"nope", 	"STR":"yep"		}'),
(7,'{						"aTTr":212,							"STR":"yep2"	}'),
(8,'{"Attr":12,							"Str":"nope11"							}')
</db_insert>

<db_create>CREATE TABLE json_attr ( id INTEGER NOT NULL, gid INTEGER NOT NULL, json1 VARCHAR(255) NOT NULL )</db_create>
<db_drop>DROP TABLE IF EXISTS `json_attr`;</db_drop>
<db_insert>
INSERT INTO json_attr ( id, gid, json1 ) VALUES
    ( 123, 1, '{"username":"Alice","year":2000,"floatkey": 1.01}' ),
    ( 234, 1, '{"username":"Bob","year":2001,"floatkey": 2.22}' ),
    ( 345, 2, '{"username":"Charlie","year":2002,"floatkey": 3.00}' ),
    ( 456, 2, '{"username":"Damon","year":2003,"floatkey": 4.44}' )
</db_insert>

<db_create>CREATE TABLE json_arrays ( id INTEGER NOT NULL, gid INTEGER NOT NULL, j VARCHAR(255) NOT NULL )</db_create>
<db_drop>DROP TABLE IF EXISTS `json_arrays`;</db_drop>
<db_insert>
INSERT INTO json_arrays ( id, gid, j ) VALUES
	( 123, 1, '{"a":[1,2,3,4], "t":["t1", "t2", "t3"]}' ),
	( 234, 1, '{"a":[2,3,4,5], "t":["t2", "t3", "t4"]}' ),
	( 345, 2, '{"a":[3,4,5,1], "t":["t3", "t4", "t5"]}' ),
	( 456, 2, '{"a":["4","5","6","2"], "t":["t4", "t5", "t6"]}' )
</db_insert>

<db_create>CREATE TABLE json_objects ( id INTEGER NOT NULL, gid INTEGER NOT NULL, j VARCHAR(255) NOT NULL )</db_create>
<db_drop>DROP TABLE IF EXISTS `json_objects`;</db_drop>
<db_insert>
INSERT INTO json_objects ( id, gid, j ) VALUES
	(1,1,'[6,[6,[6,[6,6.0]]]]'),
	(2,1,'[1, 2, 3.0, 1000000000000,["a","b","c"],{"a":"b"}]'),
	(3,1,'{"a":"tag","b":"another tag"}'),
	(4,1,'[1,2,3,[4,5,6,[7,8]]]'),
	(5,1,'{"MixedCase":"passed"}'),
	(6,2,'[1,2,3,[4,5,[6]],7,"8",{a:"b"},{},[6,6,6.0,6]]'),
	(7,2,'[1,"x",{"y":"3","assoc":{"a1":6,"a2":5,"a3":"tag1", "a4":{"b1":1,"b2":2}}}, "123"]'),
	(8,2,'{"a":{"c":"d"},"b":"c","e":6}'),
	(9,2,'[false, true, null, "15\\u00f8C"]'),
	(10,3,'{key1:{key2:{key3:"value"}}}'),
	(11,4,'{"1234":1,"123":2,"1234a":3}'),
	(12,4,'{}'),
	(13,4,'[]'),
	(14,4,'')
</db_insert>

<db_create>CREATE TABLE json_inplace ( id INTEGER NOT NULL, gid INTEGER NOT NULL, title VARCHAR(255), j VARCHAR(255) NOT NULL )</db_create>
<db_drop>DROP TABLE IF EXISTS `json_inplace`;</db_drop>
<db_insert>
INSERT INTO json_inplace ( id, gid, title, j ) VALUES
    ( 1,1,'','{"a":[1,2,3,4],"f":[1.0,3.0,2.0]}'),
    ( 2,1,'','{"a":[2,3,4,5],"f":[2.0,4.0,3.0]}'),
    ( 3,2,'','{"a":"tag1","b":"tag2"}'),
    ( 4,3,'','{"a":1,"c":2}');
</db_insert>

<db_create>CREATE TABLE json_objects1 ( id INTEGER NOT NULL, gid INTEGER NOT NULL, j VARCHAR(255) NOT NULL )</db_create>
<db_drop>DROP TABLE IF EXISTS `json_objects1`;</db_drop>
<db_insert>
INSERT INTO json_objects1 ( id, gid, j ) VALUES
	(1,1,'{"a":true,"b":"another tag"}'),
	(2,1,'{"b":"another tag"}'),
	(3,1,'{"a":false,"b":"another tag"}'),
    (4,1,'{}')
</db_insert>

<db_create>CREATE TABLE json_str_arrays ( id INTEGER NOT NULL, title VARCHAR(255) NOT NULL, j VARCHAR(255) )</db_create>
<db_drop>DROP TABLE IF EXISTS `json_str_arrays`;</db_drop>
<db_insert>
INSERT INTO json_str_arrays ( id, title, j ) VALUES
    ( 1, 'Product 1', '{"color":["blue","black","yellow"]}'),
    ( 2, 'Product 2', '{"color":["white","black","blue"]}'),
    ( 3, 'Product 3', '{"color":["black"]}'),
    ( 4, 'Product 4', NULL )
</db_insert>

<queries>
<!-- json via API -->
<query index="loc" select="*, @count" groupattr="j.uid" sortmode="extended" sortby="id asc" groupsort="id asc"/>
<query index="loc1" select="*, @count" groupattr="j.uid" sortmode="extended" sortby="id asc" groupsort="id asc"/>
<query index="dist" select="*, @count" groupattr="j.uid" sortmode="extended" sortby="id asc" groupsort="id asc"/>
<query index="dist1" select="*, @count" groupattr="j.uid" sortmode="extended" sortby="id asc" groupsort="id asc"/>
<!-- json.field via API -->
<query index="loc_field" select="bigint ( id ), j.uid, j.name" filter="j.uid" filter_range="249 1000"/>
<query index="loc_field" select="bigint ( id ), j.uid, j.name" sortmode="extended" sortby="j.name asc, j.gid desc"/>
<query index="dist_field" select="bigint ( id ), j.name, j.uid" sortmode="extended" sortby="j.name desc, j.gid asc"/>
<query index="dist_field" select="bigint ( id ), j.name, j.34, j.179, j.uid, j.sv,  j.t6, j. f2, j.f1"/>
<!-- string filter via distributed index -->
<query index="dist_str" filter="json1.username" filter_str="Alice"/>
<query index="dist_str" filter="json1.username" filter_str="Damon"/>
<!-- check json quoting via API -->
<query index="objects" select="j, j.key1.key2.key3" filter="j.key1.key2.key3" filter_str="value"/>

<!-- group by vs distributed index -->
<sphinxql>select *, count(*) from loc group by j.uid order by id asc;
select *, count(*) from loc1 group by j.uid order by id asc;
select *, count(*) from dist group by j.uid order by id asc;
select *, count(*) from dist1 group by j.uid order by id asc;
<!-- query that cause crash -->
select * from count() loc group by j.uid;

select * from test;
select * from test where j.uid&gt;200;
select * from test where j.t1&gt;0;
select * from test where j.t2&lt;0;
select * from test where j.t5&gt;0;
select * from test where j.t6&lt;0;
select * from test where j.name='Alice';
select * from test where j.name='alice';
select * from test where j.short='ohai';
select * from test where j.gid=315;
select * from test where j.gid='315';
select * from test where j.gid>315;
select * from test where j.gid=12;
select * from test where id=13;
select * from test where id=14;
<!-- ORDER BY, NULL(able) values are presented first if you do ORDER BY ... ASC and last if you do ORDER BY ... DESC -->
select id, j from test order by j.name asc, j.gid desc;
select id, j from test order by j.name desc, j.gid asc;
<!-- json.field via SphinxQL -->
select id, j.uid, j.name from loc_field where j.uid>250;
select id, j.uid, j.name from loc_field order by j.name asc, j.gid desc;
select id, j.name, j.uid from dist_field order by j.name desc, j.gid asc;
select id, j.name, j.34, j.179, j.uid, j.sv,  j.t6, j. f2, j.f1 from dist_field;
<!-- json.field case -->
select id, j.Attr as j1, j.aTTr j2, j.Str as j3, j.STR j4 from json_case;
select id, j.Attr, j.aTTr, j.Str, j.STR from json_case where j.Attr>100;
select id, j.Attr, j.aTTr, j.Str, j.STR from json_case where j.aTTr&lt;100;
select id, j.Attr, j.aTTr, j.Str, j.STR from json_case where j.Str='nope';
select id, j.Attr, j.aTTr, j.Str, j.STR from json_case where j.STR='yep';
select id, count(*) c, j.Attr, j.aTTr, j.Str, j.STR from json_case group by j.Attr;
select id, count(*) c, j.Attr, j.aTTr, j.Str, j.STR from json_case group by j.aTTr;
select id, count(*) c, j.Attr, j.aTTr, j.Str, j.STR from json_case group by j.Str;
select id, count(*) c, j.Attr, j.aTTr, j.Str, j.STR from json_case group by j.STR;
select id, j.Attr, j.aTTr, j.Str, j.STR from json_case order by j.Attr asc, id desc;
select id, j.Attr, j.aTTr, j.Str, j.STR from json_case order by j.aTTr desc, id desc;
select id, j.Attr, j.aTTr, j.Str, j.STR from json_case order by j.Str asc, id desc;
select id, j.Attr, j.aTTr, j.Str, j.STR from json_case order by j.STR desc, id desc;
<!-- json vs rt -->
insert into rt (id, title, data) values (1, 'title1','{attr1:10, attr2:"test1"}');
insert into rt (id, title, data) values (2, 'title2','{attr1:20, attr2:"test2"}');
insert into rt (id, title, data) values (3, 'title3','{attr1:30, attr2:"test3"}');
select * from rt;
select * from rt where data.attr1=20;
select * from rt group by data.attr1;
replace into rt (id, data) values (3, '{attr1:100, attr2:"replaced", new_attr:"text"}');
select * from rt;
select * from rt group by data.new_attr;
select data.attr2 from rt group by data.new_attr;
<!-- quoting check -->
select * from json_attr;
select json1.username from json_attr where id=123;
select json1.year from json_attr where id=123;
<!-- floats check -->
select * from json_attr where json1.floatkey>1.234;
select * from json_attr where json1.floatkey between 1 and 3;
select * from json_attr where json1.floatkey between 1.01 and 3.0;
select * from json_attr where json1.floatkey between 1.01 and 1.02;
select * from json_attr where json1.floatkey>2.22;
select * from json_attr where json1.floatkey>=2.22;
<!-- json in multiple -->
select *, count(*) from test group by gid, j.t1, j.gid;
<!-- type conversion -->
select double(json1.year) from json_attr;
select double(json1.floatkey) from json_attr;
select sum(integer(json1.year)) from json_attr;
select sum(double(json1.floatkey)) from json_attr;
select avg(double(json1.floatkey)) from json_attr;
select avg(integer(json1.floatkey)) from json_attr;
select min(bigint(json1.floatkey)) from json_attr;
select min(bigint(json1.year)) from json_attr;
select max(double(json1.floatkey)) from json_attr;
select max(integer(json1.floatkey)) from json_attr;
select double(json1.year) as `year` from json_attr where `year`>=2002.0;
select integer(json1.floatkey) as floatkey from json_attr where floatkey>=2;
<!-- multiple conditions -->
select * from json_attr where json1.year=2000 and json1.floatkey>=1.01;
select * from json_attr where json1.year=2000 and json1.floatkey>=1.01 and json1.username='Alice';
<!-- regression json missed on RT insert -->
insert into rt1 (id, title) values (100, 'title1' );
select * from rt1 where id=100;
<!-- filtering integers using floating point precision -->
select * from json_attr where json1.year>=2001 and json1.year&lt;2003;
select * from json_attr where json1.year>=2001.0 and json1.year&lt;2003;
select * from json_attr where json1.year>=2001.0 and json1.year&lt;2003.0;
select * from json_attr where json1.year>=2000.0001 and json1.year&lt;2003.0001;
select * from json_attr where json1.year>=2000.000001 and json1.year&lt;2003.000001;
<!-- string filter via distributed index -->
select * from dist_str where json1.username='Alice';
select * from dist_str where json1.username='Damon';
<!-- stirng filter vs escaped strings -->
select * from test where j.nick='One\nTwo';
select * from test where j.nick='one\ntwo';
select * from test where j.nick='One
Two';
<!-- array functions -->
select * from arrays;
select j.a[0] from arrays;
select j.a[2] from arrays where j.a[2]>2;
select j.a[2] from arrays order by j.a[2] desc;
select in(j.a,4,6) as p from arrays where p=1;
select j.t[2] from arrays;
select j.t[2] from arrays where j.t[2]='t3';
select j.t[2] from arrays order by j.t[2] desc;
select j.t, in(j.t,'t4','t6') as p from arrays where p=1;
select j.a[-1], j.t[-1], j.a[5], j.t[5] from arrays;
select least(j.a), greatest(j.a), least(j.t), greatest(j.t) from arrays;
<!-- fulljson subscript and null filter -->
select j from objects;
select j[0] from objects where j[0] is not null;
select j[1] from objects where j[1] is not null;
select j[2] from objects where j[2] is not null;
select j[2]['assoc'].a4 from objects where j[2]['assoc'].a4 is not null;
select j['MixedCase'], j['mixedcase'] from objects where j.MixedCase is not null;
select j[1][1][1][1] from objects where j[1][1][1][1] is not null;
select j.a[j.b] from objects where j.a[j.b] is not null;
select j[id] from objects where j[id] is not null;
select j[2*id-3] from objects where j[2*id-3] is not null;
<!-- group by array elements and containers -->
select j.a from objects group by j.a;
select j[0] from objects group by j[0];
select j[1] from objects group by j[1];
<!-- func_in for arrays and array elements -->
select j, in(j,6) as p from objects where p=1;
select j.a, in(j.a,'tag') as p from objects where p=1;
select j[0], in(j[0],1,2) as p from objects where p=1;
select j[2], in(j[2],2,3) as p from objects where p=1;
select j[3][3], in(j[3][3],7) as p from objects where p=1;
<!-- numeric fields -->
select j.1234, j.123, .1234, .123 from objects where j.1234 is not null;
select j.1234, j.1234a from objects where j.1234a is not null;
select j 0.1234 as error from objects;
<!-- aliases and null filter -->
select j from objects where j is not null;
select j as p from objects where p is not null;
select j[2]['assoc'].a4 as p from objects where p is not null;
<!-- length function -->
select length(j) from objects;
select length(j[0]) from objects;
select length(j.a) from objects;
<!-- mixed case for distributed index -->
select j.str from dist_case where j.str is not null order by j.str asc;
select j.Str from dist_case where j.Str is not null order by j.Str asc;
select j.STR from dist_case where j.STR is not null order by j.STR asc;
<!-- sort by aliased attribute for local and distributed indexes -->
select j.Str as p from json_case where p is not null order by p asc;
select j.Str as p from json_case where p is not null order by p desc;
select j.Str as p from dist_case where p is not null order by p asc;
select j.Str as p from dist_case where p is not null order by p desc;
<!-- inplace update and strict option -->
update json_inplace set j.a[0]=5 where id=1;
select * from json_inplace;
update json_inplace set j.a[0]=10.0, j.f[1]=3.1415926535 where gid=1;
select * from json_inplace;
update json_inplace set j.a[0]=-5 where id=1;
select * from json_inplace;
update json_inplace set j.a[1]=-15 where gid>0;
select * from json_inplace;
update json_inplace set j.a[1]=-20 where gid=1 option strict=1;
select * from json_inplace;
update json_inplace set j.a[1]=-30 where gid>0 option strict=1;
select * from json_inplace;
update json_inplace set j.a=5, j.c=5, j.a[0]=5 where gid>0;
select * from json_inplace;
update json_inplace set j.a=10, j.c=10, j.a[0]=10 where gid>0 option strict=1;
select * from json_inplace;
update json_inplace set j.a=15, j.c=15 where gid=3 option strict=1;
select * from json_inplace;
<!-- same for rt index -->
insert into json_inplace_rt (id, gid, title, j) values
( 1,1,'','{"a":[1,2,3,4],"f":[1.0,3.0,2.0]}'),
( 2,1,'','{"a":[2,3,4,5],"f":[2.0,4.0,3.0]}'),
( 3,2,'','{"a":"tag1","b":"tag2"}'),
( 4,3,'','{"a":1,"c":2}')
;
update json_inplace_rt set j.a[0]=5 where id=1;
select * from json_inplace_rt;
update json_inplace_rt set j.a[0]=10.0, j.f[1]=3.1415926535 where gid=1;
select * from json_inplace_rt;
update json_inplace_rt set j.a[0]=-5 where id=1;
select * from json_inplace_rt;
update json_inplace_rt set j.a[1]=-15 where gid>0;
select * from json_inplace_rt;
update json_inplace_rt set j.a[1]=-20 where gid=1 option strict=1;
select * from json_inplace_rt;
update json_inplace_rt set j.a[1]=-30 where gid>0 option strict=1;
select * from json_inplace_rt;
update json_inplace_rt set j.a=5, j.c=5, j.a[0]=5 where gid>0;
select * from json_inplace_rt;
update json_inplace_rt set j.a=10, j.c=10, j.a[0]=10 where gid>0 option strict=1;
select * from json_inplace_rt;
update json_inplace_rt set j.a=15, j.c=15 where gid=3 option strict=1;
select * from json_inplace_rt;
<!-- deadlock regression test -->
insert into json_inplace_rt (id, gid, title, j) values (666, 666, '', '{}');
<!-- scientific notation -->
insert into rt (id, data) values (4, '{"f": 1e-5}');
insert into rt (id, data) values (5, '{"f": 1e5}');
insert into rt (id, data) values (6, '{"f": -1e-5}');
insert into rt (id, data) values (7, '{"f": -1e5}');
insert into rt (id, data) values (8, '{"f": 6.022e+3}');
insert into rt (id, data) values (9, '{"f": 1.4738223E-1}');
select * from rt where id&gt;=4 and id&lt;=9;
<!-- group by json blob -->
select * from json_inplace_rt group by j;
select * from json_inplace_rt group by title, j;
<!-- search in arrays -->
insert into json_search (id, title, j) values
	(1, 'a1', '{"array":[{gid:1,name:"a1"},{gid:2,name:"a2"},{gid:3,name:"a3"}], "intarray":[1,2,3], "tags":["a1","a2","a3"]}'),
	(2, 'a5', '{"array":[{gid:4,name:"a4"},{gid:5,name:"a5"},{gid:6,name:"a6"}], "intarray":[4,5,6], "tags":["a4","a5","a6"]}'),
	(3, 'a9', '{"array":[{gid:7,name:"a7"},{gid:8,name:"a8"},{gid:9,name:"a9"}], "intarray":[7,8,9], "tags":["a7","a8","a9"]}')
;
select all(x&gt;3 and x&lt;7 for x in j.intarray) from json_search;
select any(x&gt;1 and x&lt;3 for x in j.intarray) from json_search;
select indexof(x&gt;2 and x&lt;4 for x in j.intarray) from json_search;
select all(x&gt;5 for x in j.intarray) from json_search;
select all(1+x.gid+1&gt;5 for x in j.array) from json_search;
select indexof(x.gid=any(y.gid=x.gid for y in j.array) for x in j.array) from json_search;
select id, j.array[indexof(1+x.gid=2 for x in j.array)].name as p from json_search where p is not null;
select all(z.gid=1 for x in j.array) as error_unknown_column_z from json_search;
select indexof(x.name='a2' for x in j.array) from json_search;
select indexof(x.name='a2' or x.name='a6' or x.name='a7' for x in j.array) from json_search;
select indexof(x.name='a2' or x.gid=6 or x.name='a7' for x in j.array) from json_search;
select indexof(x.name='a2' and x.gid=2 for x in j.array) from json_search;
select indexof(x.name=title for x in j.array) from json_search;
select indexof('a2'=x.name for x in j.array) from json_search;
select indexof(title=x.name for x in j.array) from json_search;
select indexof(to_string(1)=to_string(1) for x in j.array) from json_search;
select all(x='a1' for x in j.tags) from json_search;
select any(x='a3' for x in j.tags) from json_search;
select indexof(x='a5' for x in j.tags) from json_search;
<!-- type conversion in the order by clause -->
insert into json_order (id, j) values
	(1, '{i:123,d:123.0,b:12300000000}'),
	(2, '{i:23,d:23.0,b:2300000000}'),
	(3, '{i:3,d:3.0,b:300000000}')
;
select j.i from json_order order by j.i asc;
select j.i from json_order order by integer(j.i) asc;
select j.d from json_order order by j.d asc;
select j.d from json_order order by double(j.d) asc;
select j.b from json_order order by j.b asc;
select j.b from json_order order by bigint(j.b) asc;
<!-- is null expression -->
select j[0] is null, if(j[0] is null,0,1), j[0] is not null, if(j[0] is not null,0,1) from objects;
<!-- distributed order by, distributed conversion functions -->
select id, j.uid from loc1 order by j.uid asc;
select id, j.uid from loc1 order by j.uid desc;
select id, j.uid from loc1 order by integer(j.uid) asc;
select id, j.uid from loc1 order by double(j.uid) asc;
select id, j.uid from loc1 order by bigint(j.uid) asc;
<!-- distributed order by for aliases -->
select id, j.uid as p from loc1 order by p asc;
select id, j.uid as p from loc1 order by p desc;
<!-- group by JSON array elements like for MVA -->
select id, count(*), groupby() from arrays group by j.a order by count(*) asc;
select id, count(*), groupby() from arrays group by j.t order by count(*) asc;
select count(*) as p, groupby() as q from arrays group by j.t order by q asc, p desc;
<!-- doesn't work, needs to be fixed -->
<!--select count(*) as p, groupby() as q from loc1 group by j.uid order by q asc, p desc;-->
<!-- group by top-level array -->
insert into json_toplevel (id, j) values
	(1, '[1,2,3,4]'),
	(2, '[1,2,3]'),
	(3, '[1,2]'),
	(4, '["a","b","c"]'),
	(5, '["a","b"]'),
	(6, '["a"]'),
	(7, '[]'),
	(8, ''),
	(9, '{"a":"b"}'),
	(10, '{}')
;
select count(*) p, groupby() q from json_toplevel group by j order by p desc;
<!-- inserting/replacing in a JSONs index with an invalid HTML (quoting) -->
replace into rt (id, data) values (1,'{"html":"p class="document""}');
select data, data.html from rt where id=1;
replace into rt (id, data) values (1,'{"html":"p class=\"document\""}');
select data, data.html from rt where id=1;
replace into rt (id, data) values (1,'{"html":"p class=\\"document\\""}');
select data, data.html from rt where id=1;
<!-- interval function and implicit conversion -->
select j.a, interval(uint(j.a[0]),1,2,3) from arrays;
select j.a, interval(j.a[0],1,2,3) from arrays;
<!-- crash on query multiple indexes with order by UPPERCASE json.field -->
select * from json_up1, json_up2 order by j.R158S asc;
select * from json_up1, json_up2 order by j.R158S desc;
select * from json_up1, json_up2 order by j.rom asc;
select * from json_up1, json_up2 order by j.rom desc;
select * from dist_up order by j.R158S asc;
select * from dist_up order by j.R158S desc;
select * from dist_up order by j.rom asc;
select * from dist_up order by j.rom desc;
<!-- reserved keyword for distributed indexes -->
select id, j.id, j.uid from dist;
<!-- is null expression for distributed indexes -->
select id, j.uid, j.uid is null, j.uid is not null from dist;
<!-- all/any/indexof syntax for distributed indexes -->
select all(x=1 for x in j.uid), any(x='1' for x in j.uid), indexof(x.uid='1' for x in j.uid) from dist;
<!-- simple string comparison -->
select title, j.array[0].name, title='a1', j.array[0].name='a4', if(j.array[1].name='a5',0,1) from json_search;
<!-- aliases in functions -->
select j.array as some_alias, any(some_alias.name&gt;x.name for x in j.array) from json_search;
select j.intarray as p, p[1], indexof(x&gt;p[1] for x in j.intarray) from json_search;
<!-- crash (OOB) on groupby while remapping fields if there is a NULL attribute -->
insert into json_remap(id,j1,j2) values (1, '[1]','[1]'), (2, '','[2]');
select groupby() from json_remap group by j2;
<!-- group by 1-character string, case-sensitive group by, same for distributed indexes -->
select count(*), groupby() from json_up1, json_up2 group by j.t1;
select count(*), groupby() from json_up1, json_up2 group by j.T1;
select count(*), groupby() from dist_up group by j.t1;
select count(*), groupby() from dist_up group by j.T1;
<!-- json field type autoconversion in expressions, types should match -->
select integer(j.rom)=202 as p from json_up1;
select j.rom=202 as p from json_up1;
select j.rom='202' as p from json_up1;
<!-- is null vs non-json fields, json-dependent columns vs order by -->
select id as v, double(v) as dv, v is null, v is not null from dist_up;
select j.rom as v, double(v) as dv, v is null, v is not null from dist_up;
select j.rom as v, double(v) as dv, v is null, v is not null from dist_up order by dv asc;
<!-- inplace update for several 64-bit values -->
update json_inplace set j.f[0]=345345345354, j.f[1]=777 where id=1;
select j.f[0], j.f[1] from json_inplace where id=1;
update json_inplace_rt set j.f[0]=345345345354, j.f[1]=777 where id=1;
select j.f[0], j.f[1] from json_inplace_rt where id=1;
<!-- type autoconversion for 64-bit values -->
select j.f, indexof(x>345345345353 for x in j.f) as p from json_inplace where p=0;
<!-- group by aliased field -->
select id, count(*), groupby(), j.a as p from arrays where id=123 group by p;
<!-- true/false/null filtered as integers -->
select j from objects where id=9 and j[0]=0 and j[1]=1 and j[2]=0;
select j from objects where id=9 and j[0]!=1 and j[1]&gt;0 and j[2]&lt;1;
<!-- type conversion in where clause -->
select j from objects where id=9 and integer(j[0])=0 and integer(j[1])=1 and integer(j[2])=0;
select j from objects where id=9 and integer(j[0])!=1 and double(j[1])&gt;0 and bigint(j[2])&lt;1;

<!-- string filters -->
select id, j.name from test where id&lt;6 and j.name='Alice' order by id asc;
select id, j.name from test where id&lt;6 and j.name != 'Alice' order by id asc;

<!-- json bool values at group by -->
select id, groupby(), count(*), j from objects1 group by j.a order by id asc;

<!-- json in filter strings -->
select id, json1, json1.username in ( 'Alice', 'damon' ) as cnd from json_attr where cnd=1 ;
select id, json1 from json_attr where json1.username in ( 'Alice', 'damon' );
set collation_connection=libc_ci;
select id, json1, json1.username in ( 'Alice', 'damon' ) as cnd from json_attr where cnd=1 ;
select id, json1 from json_attr where json1.username in ( 'Alice', 'damon' );

<!-- json array with in filter strings -->
select id, j, j.color in ( 'blue' ) as cnd from json_str_arrays where cnd=1 order by id asc;
select id, j from json_str_arrays where j.color in ( 'blue' ) order by id asc;

</sphinxql>
</queries>
</test>
